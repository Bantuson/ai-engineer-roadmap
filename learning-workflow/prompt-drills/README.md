# Prompt Drills

Daily prompt exercises organized by category. Complete 4 drills per day (12 prompts total).

## Daily Structure

| Time | Drill | Focus | Prompts |
|------|-------|-------|---------|
| 08:00-08:30 | Drill #1 | Agent Design | 3 |
| 08:30-09:00 | Drill #2 | Prompt Techniques | 3 |
| 14:00-14:30 | Drill #3 | Security | 3 |
| 20:00-20:30 | Drill #4 | Evaluation | 3 |

## Categories

### 1. Agent Design
Focus on designing AI agent systems:
- Role definition
- Task specification
- Agent collaboration
- System architecture

### 2. Prompt Techniques
Focus on effective prompting:
- Few-shot learning
- Chain-of-thought
- Structured output
- Context management

### 3. Security
Focus on AI security:
- Injection defense
- Input validation
- Guardrails
- Red teaming

### 4. Evaluation
Focus on measuring quality:
- Quality metrics
- LLM-as-judge
- Test design
- Benchmarking

## Drill Format

Each drill file contains:
- Topic of the day
- 3 prompt exercises
- Example prompts
- Space for your responses

## Weekly Organization

```
prompt-drills/
├── week1/
│   ├── day01-drills.md
│   ├── day02-drills.md
│   ├── day03-drills.md
│   ├── day04-drills.md
│   ├── day05-drills.md
│   ├── day06-drills.md
│   └── day07-drills.md
├── week2/
│   ├── day08-drills.md
│   ├── day09-drills.md
│   ├── day10-drills.md
│   ├── day11-drills.md
│   ├── day12-drills.md
│   ├── day13-drills.md
│   └── day14-drills.md
└── week3/
    ├── day15-drills.md
    ├── day16-drills.md
    ├── day17-drills.md
    ├── day18-drills.md
    ├── day19-drills.md
    └── day20-drills.md
```

## Targets

| Week | Drills | Prompts |
|------|--------|---------|
| Week 1 | 28 (4/day × 7) | 84 |
| Week 2 | 28 | 84 |
| Week 3 | 24 (6 days) | 72 |
| **Total** | **80** | **240** |

## Tips for Effective Drills

1. **Time yourself** - 30 minutes per drill
2. **Write, don't just think** - Document all prompts
3. **Iterate** - Try multiple versions
4. **Test when possible** - Run prompts through an LLM
5. **Reflect** - Note what works and what doesn't

## Quality Checklist

For each prompt, ask:
- [ ] Is the intent clear?
- [ ] Are constraints specified?
- [ ] Is the format defined?
- [ ] Are examples provided (if needed)?
- [ ] Is it testable?

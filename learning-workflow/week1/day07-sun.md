# Day 7 - Sunday, January 25, 2026

## Day Theme
**Capstone & Review** - Deep work on eval system, reflect on Week 1.

## Schedule (Weekend: 6 Hours)

```
09:00 - 10:30  | CAPSTONE WORK
               | - Eval system development
               | - CrewAI eval script

10:30 - 11:00  | BREAK

11:00 - 13:00  | CAPSTONE CONTINUED
               | - LlamaIndex eval script
               | - Testing and refinement

13:00 - 13:30  | BREAK

13:30 - 14:30  | WEEK 1 REVIEW
               | - Gap identification
               | - Concept reinforcement

14:30 - 15:00  | WEEK 2 PLANNING
               | - Materials preparation
               | - Schedule review
```

## Capstone: Eval System Development

### CrewAI Eval Script Progress

```python
"""
eval_crewai_story.py - Implementation

Today's Tasks:
1. [ ] Complete test case setup
2. [ ] Implement story generation runner
3. [ ] Implement LLM-as-judge evaluation
4. [ ] Calculate metrics
5. [ ] Generate report
"""

# Test themes
test_themes = [
    "A cat's adventure in the city",
    "Time travel to ancient Egypt",
    "Robot learns to love",
    "Detective solves impossible crime",
    "First contact with aliens"
]

# Metrics to calculate
metrics = {
    "creativity": "1-5 scale",
    "coherence": "1-5 scale",
    "theme_adherence": "1-5 scale",
    "grammar": "1-5 scale",
    "engagement": "1-5 scale"
}
```

### LlamaIndex Eval Script Progress

```python
"""
eval_llamaindex_study.py - Implementation

Today's Tasks:
1. [ ] Set up test document corpus
2. [ ] Create test queries with expected answers
3. [ ] Implement query runner
4. [ ] Implement retrieval evaluation
5. [ ] Implement answer evaluation
"""

# Test queries
test_queries = [
    {
        "query": "What is X?",
        "expected": "X is...",
        "type": "factual"
    },
    {
        "query": "Compare X and Y",
        "expected_keywords": ["difference", "similar"],
        "type": "comparative"
    }
]
```

---

## Week 1 Reflection

### Quantitative Review

| Metric | Target | Actual | Gap |
|--------|--------|--------|-----|
| Prompts | 45 | | |
| DSA Problems | 15 | | |
| Python Days | 1-10 | | |
| PM Lessons | 4 | | |
| Mini-Projects | 2 | | |
| Reading Sessions | 5 | | |

### What Worked Well
1.
2.
3.

### What Was Challenging
1.
2.
3.

### Key Learnings
1.
2.
3.

### Concepts to Reinforce
1.
2.
3.

### Schedule Adjustments for Week 2
1.
2.

### Energy/Sustainability Check
- Sleep average: ___h
- Breaks taken: Always / Sometimes / Rarely
- Stress level: 1-5
- Motivation: 1-5

---

## Week 2 Preparation

### Materials to Review
- [ ] `week2/overview.md`
- [ ] Python Days 11-20 content
- [ ] LangGraph, LangChain documentation
- [ ] PM Technical module overview

### Topics Coming Up
**Python:** API requests, web scraping, testing, debugging
**Mini-Projects:** LangGraph, LangChain, OpenAI SDK, Pydantic AI
**PM:** Technical PM, PRD writing, APIs, Agile
**DSA:** Linked lists, trees, more patterns

### Week 2 Goals
1.
2.
3.

---

## End of Day Checklist

- [ ] CrewAI eval script progress
- [ ] LlamaIndex eval script progress
- [ ] Week 1 reflection complete
- [ ] Week 2 materials reviewed
- [ ] Schedule confirmed
- [ ] Rest planned

## Tomorrow Preview (Day 8 - Monday)
- Full weekday schedule resumes
- Reading: evals/03-testing-ai-features
- Python Days 11-12 (API GET/POST)
- LangGraph setup (new project!)
- PM: Technical PM intro
- DSA: Linked lists
